{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import pinecone, Pinecone, Qdrant\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,glob=\"*.pdf\",loader_cls=PyPDFLoader) #if we send a directory only pdf files are loaded and each loader class is pypdfloader\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create chunks to give to the llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap = 20)\n",
    "    text_chunk = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = chunker(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total documents are divided into 6983 chunks\n"
     ]
    }
   ],
   "source": [
    "print(\"total documents are divided into\",len(text_chunks),\"chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert these into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings=download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lets convert our words into embeddings using hugging face embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_example = embeddings.embed_query(\"hi everyone\")\n",
    "len(embedding_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coverting all our data into embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### using pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.vectorstores import Pinecone as p2\n",
    "# from pinecone import Pinecone\n",
    "# PINECONE_API_KEY = \"8af77b04-8a9a-4a21-9a71-b1027067fa63\"\n",
    "# PINECONE_API_INDEX = \"us-east-1\"\n",
    "# pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "# index= pc.Index(\"airamatrix-chatbot\")\n",
    "\n",
    "# docsearch = p2.from_texts([t.page_content for t in text_chunks], embeddings, index_name = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### using qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(api_key=\"wRvbWrE136bxNLjPBGlTTt27VfNtrWxpWk9NYm3eYMjvVcsj8v-ryQ\", url=\"https://a3e797dc-0ae6-4e96-8392-4bff15d64ae6.europe-west3-0.gcp.cloud.qdrant.io:6333\")\n",
    "\n",
    "# Step 3: Create a collection in Qdrant\n",
    "embedding_size = 384  # Adjust this based on the Hugging Face model output size (384 for all-MiniLM-L6-v2)\n",
    "client.create_collection(\n",
    "    collection_name=\"text_embeddings\",\n",
    "    vectors_config={\n",
    "        \"size\": embedding_size,  # Dimensionality of the embeddings\n",
    "        \"distance\": \"Cosine\"  # You can choose \"Cosine\", \"Euclidean\", or \"Dot\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_all = []\n",
    "for index,val in enumerate(text_chunks):\n",
    "    print(f\"Index: {index}\", end='\\r')\n",
    "    embeddings_all.append(embeddings.embed_query(val.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6900\r"
     ]
    }
   ],
   "source": [
    "points = [\n",
    "        {\"id\": idx, \"vector\": embedding, \"payload\": {\"text\": chunk}}\n",
    "        for idx, (chunk, embedding) in enumerate(zip(text_chunks, embeddings_all))\n",
    "    ]\n",
    "\n",
    "def batch_upsert(client, collection_name, points, batch_size=100):\n",
    "    for i in range(0, len(points), batch_size):\n",
    "        print(f\"{i}\",end='\\r')\n",
    "        batch = points[i:i + batch_size]\n",
    "        client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=batch\n",
    "        )   \n",
    "\n",
    "# Step 5: Insert the embeddings in batches\n",
    "batch_upsert(client, \"text_embeddings\", points, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### searching a query's similar parts in qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 6028, Score: 0.766492, Text: {'page_content': 'ORGANIZATIONS\\nAmerican Academy of Ophthalmology. 655 Beach Street, PO\\nBox 7424, San Francisco, CA 94120-7424. <http://www.\\neyenet.org>.KEY TERMS\\nAllergen —A substance capable of inducing an\\nallergic response.\\nAllergic reaction —An immune system reaction to\\na substance in the environment; symptoms\\ninclude rash, inflammation, sneezing, itchy watery\\neyes, and runny nose.\\nConjunctiva —The mucous membrane that covers\\nthe white part of the eyes and lines the eyelids.', 'metadata': {'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 659}}\n",
      "ID: 3965, Score: 0.6300445, Text: {'page_content': 'Although environmental medicine is gaining more\\nrespect within conventional medicine, detoxificationKEY TERMS\\nAllergen —A foreign substance, such as mites in\\nhouse dust or animal dander, that when\\ninhaled,causes the airways to narrow and pro-\\nduces symptoms of asthma.\\nAntibody —A protein, also called immunoglobu-\\nlin, produced by immune system cells to remove\\nantigens (the foreign substances that trigger the\\nimmune response).\\nFibromyalgia —A condition of debilitating pain,', 'metadata': {'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 431}}\n",
      "ID: 3949, Score: 0.505505, Text: {'page_content': 'allergy tests are used to determine a patient’s sensitivity\\nto a variety of common substances, including formalde-\\nhyde, auto exhaust, perfume, tobacco, chlorine, jet fuel,\\nand other chemicals.\\nFood allergies require additional tests because these\\nallergies often cause reactions that are delayed for several\\ndays after the food is eaten. The RAST (radioallergosor-\\nbent test) is a blood test that determines the level of anti-\\nbodies (immunoglobulins) in the blood after specific', 'metadata': {'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 429}}\n"
     ]
    }
   ],
   "source": [
    "example_query_chunk = \"what are allergies\"  \n",
    "example_query_embedding = embeddings.embed_query(example_query_chunk)\n",
    "\n",
    "results = client.search(\n",
    "    collection_name=\"text_embeddings\",\n",
    "    query_vector=example_query_embedding,\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"ID: {result.id}, Score: {result.score}, Text: {result.payload['text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above ranked result looks similar to the question but the answer is not readable and somewhat random, so we use our llm to give the correct result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs = {\"prompt\":PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model=\"llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                    model_type=\"llama\",\n",
    "                    config={'max_new_tokens':512,\n",
    "                    'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the qdrant database entity\n",
    "qdrant = Qdrant(client=client, collection_name=\"text_embeddings\", embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "#                                 chain_type=\"stuff\",\n",
    "#                                 retriever=qdrant.as_retriever (search_kwargs={'k': 2}),\n",
    "#                                 return_source_documents=True,\n",
    "#                                 chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Document\npage_content\n  none is not an allowed value (type=type_error.none.not_allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mqa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhat is an medicine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\chains\\base.py:181\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    182\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    183\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    184\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    185\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\chains\\base.py:175\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    169\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    170\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    171\u001b[0m     inputs,\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 175\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:128\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    124\u001b[0m accepts_run_manager \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs)\u001b[38;5;241m.\u001b[39mparameters\n\u001b[0;32m    126\u001b[0m )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_run_manager:\n\u001b[1;32m--> 128\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:208\u001b[0m, in \u001b[0;36mRetrievalQA._get_docs\u001b[1;34m(self, question, run_manager)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_docs\u001b[39m(\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    203\u001b[0m     question: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    205\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[0;32m    206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get docs.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\schema\\retriever.py:181\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    184\u001b[0m         result,\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    186\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\schema\\retriever.py:174\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 174\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    175\u001b[0m         query, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\vectorstores\\base.py:413\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 413\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    415\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    416\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[0;32m    417\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\vectorstores\\qdrant.py:216\u001b[0m, in \u001b[0;36mQdrant.similarity_search\u001b[1;34m(self, query, k, filter, search_params, offset, score_threshold, consistency, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    175\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    183\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    184\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(\n\u001b[0;32m    217\u001b[0m         query,\n\u001b[0;32m    218\u001b[0m         k,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[0;32m    220\u001b[0m         search_params\u001b[38;5;241m=\u001b[39msearch_params,\n\u001b[0;32m    221\u001b[0m         offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    222\u001b[0m         score_threshold\u001b[38;5;241m=\u001b[39mscore_threshold,\n\u001b[0;32m    223\u001b[0m         consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[38;5;241m0\u001b[39m), results))\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\vectorstores\\qdrant.py:273\u001b[0m, in \u001b[0;36mQdrant.similarity_search_with_score\u001b[1;34m(self, query, k, filter, search_params, offset, score_threshold, consistency, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    230\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m        Lower score represents more similarity.\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_query(query),\n\u001b[0;32m    275\u001b[0m         k,\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[0;32m    277\u001b[0m         search_params\u001b[38;5;241m=\u001b[39msearch_params,\n\u001b[0;32m    278\u001b[0m         offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    279\u001b[0m         score_threshold\u001b[38;5;241m=\u001b[39mscore_threshold,\n\u001b[0;32m    280\u001b[0m         consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    282\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\vectorstores\\qdrant.py:412\u001b[0m, in \u001b[0;36mQdrant.similarity_search_with_score_by_vector\u001b[1;34m(self, embedding, k, filter, search_params, offset, score_threshold, consistency, **kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m     query_vector \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_name, embedding)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    399\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m    400\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name,\n\u001b[0;32m    401\u001b[0m     query_vector\u001b[38;5;241m=\u001b[39mquery_vector,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    411\u001b[0m )\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    413\u001b[0m     (\n\u001b[0;32m    414\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_document_from_scored_point(\n\u001b[0;32m    415\u001b[0m             result, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontent_payload_key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_payload_key\n\u001b[0;32m    416\u001b[0m         ),\n\u001b[0;32m    417\u001b[0m         result\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    420\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\vectorstores\\qdrant.py:414\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    397\u001b[0m     query_vector \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_name, embedding)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    399\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m    400\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name,\n\u001b[0;32m    401\u001b[0m     query_vector\u001b[38;5;241m=\u001b[39mquery_vector,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    411\u001b[0m )\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    413\u001b[0m     (\n\u001b[1;32m--> 414\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_document_from_scored_point\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent_payload_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata_payload_key\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    417\u001b[0m         result\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    420\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\vectorstores\\qdrant.py:761\u001b[0m, in \u001b[0;36mQdrant._document_from_scored_point\u001b[1;34m(cls, scored_point, content_payload_key, metadata_payload_key)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_document_from_scored_point\u001b[39m(\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    759\u001b[0m     metadata_payload_key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    760\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Document:\n\u001b[1;32m--> 761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscored_point\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_payload_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscored_point\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_payload_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\karth\\OneDrive\\Desktop\\medical chatbot\\medicalenv\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for Document\npage_content\n  none is not an allowed value (type=type_error.none.not_allowed)"
     ]
    }
   ],
   "source": [
    "# qa({\"query\":\"what is an medicine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=4 version=0 score=1.0 payload={'text': {'page_content': 'Mary Beth Trimper, Manager, Composition and\\nElectronic Prepress\\nEvi Seoud, Assistant Manager, Composition Purchasing\\nand Electronic Prepress\\nDorothy Maki, Manufacturing Manager\\nWendy Blurton, Senior Manufacturing SpecialistThe GALE\\nENCYCLOPEDIA\\nof MEDICINE\\nSECOND EDITIONSince this page cannot legibly accommodate all copyright notices, the\\nacknowledgments constitute an extension of the copyright notice.\\nWhile every effort has been made to ensure the reliability of the infor-', 'metadata': {'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 2}}} vector=None shard_key=None order_value=None\n",
      "id=52 version=0 score=0.39725316 payload={'text': {'page_content': 'Belleville, MI\\nAnna Rovid Spickler, D.V .M.,\\nPh.D.\\nMedical Writer\\nMoorehead, KY\\nGALE ENCYCLOPEDIA OF MEDICINE 2 XVIContributors', 'metadata': {'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 11}}} vector=None shard_key=None order_value=None\n",
      "id=3 version=0 score=0.39572525 payload={'text': {'page_content': 'Multimedia Content\\nKelly A. Quin, Editor, Imaging and Multimedia Content\\nLeitha Etheridge-Sims, Mary K. Grimes, Dave Oblender,\\nImage Catalogers\\nPamela A. Reed, Imaging Coordinator\\nRandy Bassett, Imaging Supervisor\\nRobert Duncan, Senior Imaging Specialist\\nDan Newell, Imaging Specialist\\nChristine O’Bryan, Graphic Specialist\\nMaria Franklin, Permissions Manager\\nMargaret A. Chamberlain, Permissions Specialist\\nMichelle DiMercurio, Senior Art Director\\nMike Logusz, Graphic Artist', 'metadata': {'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 2}}} vector=None shard_key=None order_value=None\n",
      "id=2463 version=24 score=0.39504135 payload={'text': {'page_content': 'are made of polyurethane and are inserted into the vaginal\\nGALE ENCYCLOPEDIA OF MEDICINE 2 880Condom', 'metadata': {'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 268}}} vector=None shard_key=None order_value=None\n",
      "id=22 version=0 score=0.3929782 payload={'text': {'page_content': 'point the reader to related entries in the encyclopedia.\\nGALE ENCYCLOPEDIA OF MEDICINE 2 IXINTRODUCTION', 'metadata': {'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 5}}} vector=None shard_key=None order_value=None\n"
     ]
    }
   ],
   "source": [
    "results = client.search(collection_name='text_embeddings', query_vector=[-0.09936315,0.027253166,0.016290115,-0.06584516,0.0026523904,0.010003437,0.04731847,0.064257585,0.020044582,-0.006465578,0.03688363,0.0022618358,0.029348977,-0.038033847,-0.08519824,0.01185296,0.028494356,0.00101958,-0.02157071,-0.027277663,-0.05679168,0.104634926,-0.018505424,0.10594168,-0.009211808,-0.022340616,-0.020207766,0.022616636,0.0049929176,-0.062917106,-0.027551604,0.06748536,0.116646454,0.025340166,-0.00027055418,0.06465472,0.00627242,0.028733863,0.034282636,-0.047342155,-0.02968264,-0.1375389,-0.059761725,-0.022104857,0.005853779,-0.004589746,0.0040081786,-0.00084610324,-0.05258,0.06526106,-0.08504582,-0.078862734,0.0026854905,-0.04362668,0.02568419,-0.027480764,-0.00969977,0.025741128,-0.09002936,0.012319594,-0.04848561,0.014403512,-0.04199979,0.053765725,0.028031569,-0.03340566,0.04795561,0.03511659,-0.054726206,-0.0341945,0.030487625,-0.05787501,-0.04245497,0.11668653,0.0019945477,0.013436567,0.048314672,-0.019335123,-0.017273467,-0.00096989766,-0.01909259,-0.028856175,0.047625866,0.06307406,-0.04280542,-0.012010276,0.0109640965,0.041824345,0.027585812,-0.052495375,0.0137157,-0.042887244,0.104532145,-0.0055549904,-0.07430501,-0.025115734,-0.13064004,-0.0452433,0.033812735,0.061831854,-0.05972457,0.050162923,-0.014383476,-0.0155252395,-0.026058862,-0.10729751,0.075774856,0.006790568,0.030540029,0.009301123,0.03540338,0.022003451,-0.05778112,-0.12022722,0.011911775,-0.03325556,-0.055778477,-0.026655626,0.11680712,-0.082031906,-0.015039398,-0.02495332,-0.06899492,-0.002497299,0.015141857,-0.07117554,0.023742089,7.139217e-33,-0.011343036,0.059683997,0.10610434,0.08368759,0.07129261,0.05737959,0.0060169767,-0.006130615,-0.005148727,-0.06858818,0.0024346109,-0.007994475,-0.008935968,-0.04279309,-0.022286149,-0.0018285991,-0.05244106,0.13636069,0.03427796,0.04702207,-0.0067098485,-0.0137336,-0.055037923,0.072831444,-0.009110314,0.040960174,-0.04284731,-0.0772926,0.049301304,0.018508531,0.043941356,0.003294207,0.03475551,-0.08575012,-0.008862936,0.05805665,-0.04547787,-0.0060103093,0.011360141,-0.0049437704,-0.017243514,0.0018986247,0.063407406,-0.021331646,-0.069662504,0.027831422,-0.023941837,-0.014502769,0.05657056,0.052836835,-0.04150654,0.013006938,0.030213423,0.014347492,0.022308772,-0.0270985,-0.052540507,-0.04022274,0.080827385,0.043524664,-0.050604653,0.15031278,-0.015544732,0.050047223,0.055257063,-0.0248857,-0.01660731,-0.1290537,0.071852274,-0.00227808,-0.0783643,0.008754057,0.027092787,-0.0032363636,-0.0454612,0.018945867,-0.09321763,-0.019936047,0.0483978,-0.041456077,-0.011089634,-0.047203936,0.024113491,0.0054624756,-0.0223571,-0.027957313,-0.017341383,0.036395688,-0.061787035,0.08659641,0.036848973,0.009364445,-0.06924029,0.07825453,-0.051732585,-7.476423e-33,0.0065238154,-0.054341357,0.009067737,0.019065695,0.036946554,0.0052025067,-0.03932375,0.038125154,-0.016341604,-0.064711556,0.097840406,-0.019697921,-0.057045765,0.012534895,-0.08913203,0.08416152,0.004972375,-0.030158456,-0.072740875,-0.022043798,-0.00054798694,0.016812857,-0.015029434,0.09134139,-0.0072841654,0.07021818,0.07465535,0.027852466,0.009751024,0.031381976,-0.026237456,-0.054850433,-0.07964397,-0.032076746,-0.055904005,-0.07853458,0.029597541,0.10054411,-0.012512837,-0.023013422,0.09065469,0.03392247,-0.035214785,0.06838911,0.02405618,-0.10051962,0.022738473,-0.04215522,0.10045284,0.016282685,-0.0029047155,-0.08452051,0.059909113,-0.054032005,0.00024363752,0.020498103,-0.002800752,-0.039312758,-0.009737797,0.00013561366,0.06430831,0.058606207,-0.08065936,0.010076022,0.028983952,-0.021660788,0.05873717,0.07695506,-0.03409168,-0.026596395,-0.010531089,0.039438985,0.01572373,-0.13566533,0.038025945,-0.045544654,0.021889549,-0.052433953,-0.08224805,-0.012906284,-0.010547632,-0.024927316,0.020821242,0.07123105,0.011760243,0.012705059,-0.012629896,-0.014167557,-0.04111902,-0.04707522,-0.055658266,0.05335863,-0.057033233,0.011704885,-0.09349584,-5.273776e-8,0.02229678,-0.0065247756,-0.0039439257,-0.05613098,0.008905925,-0.012458816,0.05326692,-0.0021884209,-0.0022493931,-0.0040118108,0.0036101323,0.014603288,-0.022723256,-0.008615941,0.09783056,-0.04650174,-0.018236972,0.06102667,-0.07421959,-0.05166894,0.03053105,-0.019958636,0.04878974,-0.10440465,-0.0018717324,0.03587195,-0.03716304,0.006407874,0.023204384,0.047745716,-0.019264163,0.1376471,0.040627945,0.029062305,0.058445506,-0.10899015,0.072846554,-0.047288984,-0.048688054,0.038972687,-0.07822044,-0.045934793,-0.01716378,0.06044081,0.08129946,-0.018590871,0.07931559,-0.038107753,0.011006298,-0.049219728,0.055462167,0.024282917,0.090294965,0.0809727,-0.046198852,0.0019319723,0.059580427,-0.00075013563,-0.002071954,-0.005340233,0.079135485,-0.08694187,0.11837327,0.025860742], limit=5)\n",
    "\n",
    "# Print the retrieved results\n",
    "for result in results:\n",
    "    print(result)  # Look at the structure of the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The Cochlear Implant is a device that helps people with severe hearing loss or deafness to hear sound again. It has two parts: an external microphone and a receiver/stimulator inside the skilled that converts sound processor that stimulator implantimer that converts sound processor that converts sound, which are too convert speech sounds are placed inverter that converts sound is located underneu\n",
      "     imulator that stimulator that is placed on the inner ear that converts sound processor. \n",
      "    Implant that converts sound processor that converts sound;;;mimulator that stimulator implantemerator inside the person to convert sound processor that converts sound that is inside the microchimulator implantibulator that stimulator that stimulator inside the enderilimulator that stimulator that stimulator, and itmorabilizer, which are placed inside the internal device that converts sound processor.\n",
      "     When itmotivmulater/ imulator implantamulator that is located underneimulator that stimulator implantifier that is connected to convert sound to convert sound processor inu-immer,i\n",
      "    Implant that stimulator that stimulator that converts sound processor that are inserted surgically, which converts sound processor. \n",
      "     The microchm that is placed inside the inner ear, and other, and that stimulator that stimulator that is located underneimeter.imulator that is placed inverter that is placed inside the brain.\n",
      "processor implantomer that stimulator implantrumul-immer that converts sound processor inside the inside the patch on the inner ear; \n"
     ]
    }
   ],
   "source": [
    "def query_database(query):\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "    # Step 2: Search Qdrant\n",
    "    results = client.search(collection_name='text_embeddings', query_vector=query_embedding,limit=3)\n",
    "    # print(results[:].payload['text']['page_content'])\n",
    "\n",
    "    stringed_results = [i.payload['text']['page_content'] for i in results]\n",
    "    combined_results = \" \".join(stringed_results)\n",
    "    # print(combined_results)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    for this query: \"{query}\"\n",
    "\n",
    "    refer to this information:\n",
    "    {combined_results}\n",
    "\n",
    "    Give a meaningful answer to the query by reading given information. Must be meaningful sentence.\n",
    "    \"\"\"\n",
    "    return llm(prompt)   \n",
    "    # if results:\n",
    "    #     combined_results = \" \".join(stringed_results)  # Adjust formatting as necessary\n",
    "    #     final_answer = llm.generate(stringed_results)  # Adjust this to match your LLM API\n",
    "    #     return final_answer\n",
    "    # else:\n",
    "    #     return \"No relevant results found.\"\n",
    "\n",
    "user_query = \"What is cochlear implant?\"\n",
    "answer = query_database(user_query)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
